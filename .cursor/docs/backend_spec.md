# Steam Review Analysis System - Technical Specification V1

## 1. Overview

This document outlines the technical design for a system to continuously fetch, translate, analyze, and store Steam game reviews for a predefined list of applications. The initial focus is on building the backend data pipeline, including data storage in PostgreSQL and an automated job to keep the review data current. Reporting and UI layers will be deferred.

The system aims to provide a structured and enriched dataset suitable for flexible analysis and reporting by storing not only raw review data and translations but also per-review structured analysis generated by an LLM (e.g., sentiment, themes, bug reports).

## 2. System Architecture

The backend will consist of the following core components:

*   **Configuration Management:** A mechanism to define the list of Steam App IDs to track.
*   **Scheduler:** An external system (like `cron`) or an internal library (`APScheduler`) to trigger the data fetching process periodically.
*   **Data Fetching Service:** Responsible for querying the Steam API for *new* reviews for tracked applications since the last fetch.
*   **Data Processing Service:** Handles translation of non-English reviews and performs per-review structured analysis using the OpenAI API.
*   **Database Interface (ORM):** Manages interaction with the PostgreSQL database (e.g., using SQLAlchemy).
*   **PostgreSQL Database:** Stores tracked applications, review data, translations, and structured analysis results.

```mermaid
graph TD
    A[Scheduler (Cron/APScheduler)] -- Triggers --> B(Main Process / Orchestrator);
    B -- Gets Tracked Apps --> C{PostgreSQL DB};
    C -- Returns Apps & Last Fetch Time --> B;
    B -- Requests New Reviews --> D[Data Fetching Service (Steam API Client)];
    D -- Fetches from Steam --> E[Steam API];
    E -- Returns Raw Reviews --> D;
    D -- Sends New Raw Reviews --> B;
    B -- Stores Raw Reviews --> C;
    B -- Triggers Processing --> F[Data Processing Service];
    F -- Gets Untranslated Reviews --> C;
    F -- Sends for Translation --> G[OpenAI API Client (Translate)];
    G -- Gets Translations --> F;
    F -- Updates Translations in DB --> C;
    F -- Gets Untranslated Reviews for Analysis --> C;
    F -- Sends for Structured Analysis --> H[OpenAI API Client (Analyze)];
    H -- Gets Structured Analysis --> F;
    F -- Updates Analysis Fields in DB --> C;
    B -- Updates Last Fetch Time --> C;

    style C fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:1px
    style G fill:#cfc,stroke:#333,stroke-width:1px
    style H fill:#cfc,stroke:#333,stroke-width:1px

```

## 3. Database Schema (PostgreSQL)

Two primary tables are proposed:

**Table 1: `tracked_apps`**
*Purpose: Stores the list of App IDs to monitor.*

| Column Name             | Data Type             | Constraints             | Description                                      |
| :---------------------- | :-------------------- | :---------------------- | :----------------------------------------------- |
| `app_id`                | INTEGER               | PRIMARY KEY             | Steam Application ID                             |
| `name`                  | VARCHAR(255)          |                         | Name of the game (optional, for reference)     |
| `last_fetched_timestamp`| BIGINT                |                         | UNIX timestamp of the newest review fetched last |
| `added_at`              | TIMESTAMP WITH TIME ZONE | DEFAULT CURRENT_TIMESTAMP | When the app was added to tracking               |
| `is_active`             | BOOLEAN               | DEFAULT TRUE            | Flag to enable/disable fetching for this app   |

**Table 2: `reviews`**
*Purpose: Stores individual review data, translations, and structured analysis.*

| Column Name                      | Data Type                | Constraints        | Description                                                    |
| :------------------------------- | :----------------------- | :----------------- | :------------------------------------------------------------- |
| `recommendationid`               | BIGINT                   | PRIMARY KEY        | Unique ID from Steam                                           |
| `app_id`                         | INTEGER                  | FOREIGN KEY (`tracked_apps`) | Steam App ID                                                 |
| `author_steamid`                 | VARCHAR(30)              |                    | Steam ID of the author                                         |
| `original_language`              | VARCHAR(20)              | NOT NULL           | Language code provided by Steam (e.g., 'schinese', 'japanese') |
| `original_review_text`           | TEXT                     |                    | The review text as fetched from Steam                          |
| `english_translation`            | TEXT                     | NULLABLE           | English translation (if applicable)                            |
| `translation_status`             | VARCHAR(20)              | DEFAULT 'pending'  | 'pending', 'translated', 'failed', 'not_required', 'skipped'   |
| `translation_model`              | VARCHAR(50)              | NULLABLE           | OpenAI model used for translation                              |
| `analysis_status`                | VARCHAR(20)              | DEFAULT 'pending'  | 'pending', 'analyzed', 'failed', 'not_required'                |
| `analyzed_sentiment`             | VARCHAR(20)              | NULLABLE           | Sentiment derived from LLM analysis ('Positive', 'Negative', 'Mixed', 'Neutral') |
| `positive_themes`                | TEXT[]                   | NULLABLE           | Array of positive themes identified by LLM                     |
| `negative_themes`                | TEXT[]                   | NULLABLE           | Array of negative themes identified by LLM                     |
| `feature_requests`               | TEXT[]                   | NULLABLE           | Array of feature requests identified by LLM                    |
| `bug_reports`                    | TEXT[]                   | NULLABLE           | Array of bug reports identified by LLM                         |
| `llm_analysis_model`             | VARCHAR(50)              | NULLABLE           | OpenAI model used for structured analysis                      |
| `llm_analysis_timestamp`         | TIMESTAMP WITH TIME ZONE | NULLABLE           | When the structured analysis was performed                     |
| `timestamp_created`              | BIGINT                   | NOT NULL           | UNIX timestamp when the review was created                     |
| `timestamp_updated`              | BIGINT                   | NOT NULL           | UNIX timestamp when the review was last updated                |
| `voted_up`                       | BOOLEAN                  | NOT NULL           | Steam thumbs up/down                                           |
| `votes_up`                       | INTEGER                  | DEFAULT 0          | Number of "helpful" votes                                      |
| `votes_funny`                    | INTEGER                  | DEFAULT 0          | Number of "funny" votes                                        |
| `weighted_vote_score`            | NUMERIC(10, 9)           | DEFAULT 0.0        | Steam's helpfulness score                                      |
| `comment_count`                  | INTEGER                  | DEFAULT 0          | Number of comments on the review                               |
| `steam_purchase`                 | BOOLEAN                  | DEFAULT FALSE      | If purchased on Steam                                          |
| `received_for_free`              | BOOLEAN                  | DEFAULT FALSE      | If received for free                                           |
| `written_during_early_access`    | BOOLEAN                  | DEFAULT FALSE      | If written during Early Access                                 |
| `developer_response`             | TEXT                     | NULLABLE           | Developer's response text                                      |
| `timestamp_dev_responded`        | BIGINT                   | NULLABLE           | UNIX timestamp of developer response                           |
| `author_num_games_owned`         | INTEGER                  | DEFAULT 0          | Author metadata                                                |
| `author_num_reviews`             | INTEGER                  | DEFAULT 0          | Author metadata                                                |
| `author_playtime_forever`        | INTEGER                  | DEFAULT 0          | Author metadata (total playtime in minutes)                   |
| `author_playtime_last_two_weeks` | INTEGER                  | DEFAULT 0          | Author metadata (playtime last 2 weeks in minutes)             |
| `author_playtime_at_review`      | INTEGER                  | DEFAULT 0          | Author metadata (playtime when reviewed in minutes)            |
| `author_last_played`             | BIGINT                   | DEFAULT 0          | Author metadata (UNIX timestamp)                             |
| `db_inserted_at`                 | TIMESTAMP WITH TIME ZONE | DEFAULT CURRENT_TIMESTAMP | When the row was inserted                                    |
| `db_last_updated_at`             | TIMESTAMP WITH TIME ZONE | DEFAULT CURRENT_TIMESTAMP | When the row was last updated                                  |

**Indices:**
*   `reviews(app_id)`
*   `reviews(app_id, timestamp_created)`
*   `reviews(original_language)`
*   `reviews(translation_status)`
*   `reviews(analysis_status)`

**Notes on Schema:**
*   Storing timestamps as `BIGINT` (Unix seconds) matches Steam's format but can be converted `TO_TIMESTAMP()` in SQL or application logic for readability. Alternatively, store as `TIMESTAMP WITH TIME ZONE`.
*   Using `TEXT[]` (PostgreSQL array of text) for themes/requests/bugs allows storing multiple items directly. This is efficient for retrieval but slightly more complex to query than normalized tables. For this stage, it's a reasonable trade-off.
*   `translation_status` and `analysis_status` columns are crucial for managing the processing pipeline and retrying failures.

## 4. Data Flow and Processing Logic

**Scheduled Job (e.g., daily cron):**

1.  **Get Tracked Apps:** Query the `tracked_apps` table for all rows where `is_active = TRUE`.
2.  **Iterate Through Apps:** For each active `app_id`:
    a.  Retrieve `last_fetched_timestamp` from `tracked_apps`.
    b.  **Fetch New Reviews:** Call the `SteamAPI` client (from `src/steam_client.py`).
        *   The client needs modification. Instead of fetching a fixed number (`max_reviews`), it should fetch reviews page by page (`num_per_page=100`, `filter='recent'`), starting with the initial cursor.
        *   On each page, process reviews *only if* their `timestamp_created` is greater than the `last_fetched_timestamp` for that app.
        *   Continue fetching pages until a review is encountered whose `timestamp_created` is *less than or equal to* `last_fetched_timestamp`, or until Steam returns no more reviews. This ensures we only process new ones. Track the highest `timestamp_created` seen in *this* fetch run.
    c.  **Store Raw Reviews:** For each newly fetched review:
        *   Perform an `INSERT INTO reviews (...) VALUES (...) ON CONFLICT (recommendationid) DO NOTHING`. This efficiently adds new reviews and ignores duplicates if Steam returns overlapping data. Populate all columns derived directly from Steam data. Set `translation_status` and `analysis_status` to `'pending'`. Determine `translation_status` based on `original_language` (e.g., set to `'not_required'` if `original_language` is 'english').
    d.  **Update Last Fetch Time:** After processing all new reviews for the app, update `last_fetched_timestamp` in the `tracked_apps` table to the highest `timestamp_created` encountered during this run.

**Data Processing (Can run immediately after fetch or as separate scheduled jobs):**

1.  **Translation Job:**
    a.  Query `reviews` table for rows where `translation_status = 'pending'` and `original_language != 'english'`.
    b.  For each review, call the `Translator` service (potentially refactored from `src/prototype.py`).
    c.  Update the corresponding row in `reviews` with the `english_translation`, `translation_model`, and set `translation_status` to `'translated'` or `'failed'`.
2.  **Per-Review Analysis Job:**
    a.  Query `reviews` table for rows where `analysis_status = 'pending'` AND (`translation_status = 'translated'` OR `translation_status = 'not_required'`).
    b.  For each review, get the `english_translation` (or `original_review_text` if English).
    c.  Call a new `ReviewAnalyzer` service. This service uses an LLM (via `src/openai_client.py`) with a specific prompt to extract structured information (sentiment, themes, bugs, features) for *that single review*.
        *   **Prompt Engineering:** This prompt needs careful crafting. Example: "Analyze the following Steam review text. Respond ONLY with a valid JSON object containing these keys: 'sentiment' (string: 'Positive', 'Negative', 'Mixed', 'Neutral'), 'positive_themes' (list of strings), 'negative_themes' (list of strings), 'feature_requests' (list of strings), 'bug_reports' (list of strings). Text: {review_text}". Use Pydantic for validation on the receiving end.
    d.  Update the corresponding row in `reviews` with the extracted fields (`analyzed_sentiment`, `positive_themes`, etc.), `llm_analysis_model`, `llm_analysis_timestamp`, and set `analysis_status` to `'analyzed'` or `'failed'`.

## 5. LLM Integration

*   **Translation:** Continue using the refined prompt from `src/prototype.py`, ensuring it handles various languages based on the `original_language` field.
*   **Structured Analysis (Per-Review):** Design a new prompt specifically for extracting structured fields from a *single* review's text (translated or original English). Request JSON output and validate using a Pydantic model mirroring the target DB columns (`analyzed_sentiment`, `positive_themes`, etc.). This replaces the previous *batch summary* analysis prompt.

## 6. Error Handling and Logging

*   Implement robust logging throughout all services.
*   Use retry mechanisms (like `tenacity`) for API calls (Steam, OpenAI).
*   Utilize the `translation_status` and `analysis_status` fields to track progress and potentially retry failed operations.
*   Handle database connection errors gracefully.

## 7. Configuration

*   `app_ids` will be managed in the `tracked_apps` table. A separate script or simple admin interface could be used to add/remove/activate/deactivate apps.
*   API Keys (`OPENAI_API_KEY`) and Database Credentials should be stored securely using environment variables (`python-dotenv`).

## 8. Scheduling

*   Initial implementation can rely on system `cron` to run the main fetching script (e.g., `./.venv/bin/python -m src.main_fetcher`) daily or hourly.
*   Processing (translation, analysis) can be triggered immediately after fetching within the same script or run as separate scheduled tasks targeting rows with 'pending' status. Separate tasks offer more resilience and scalability.

## 9. Technology Stack (Initial Backend Focus)

*   **Language:** Python 3.9+
*   **Database:** PostgreSQL 13+
*   **ORM:** SQLAlchemy
*   **DB Driver:** `psycopg2-binary` (sync) or `asyncpg` (if async architecture is chosen later)
*   **API Clients:** `requests` (Steam), `openai` (OpenAI SDK)
*   **Scheduling:** System `cron` (initially) or `APScheduler` (for in-process scheduling)
*   **Config:** `python-dotenv`
*   **Validation:** `pydantic`

## 10. Initial Implementation Focus

1.  Set up PostgreSQL database and define the schema using SQLAlchemy models.
2.  Refactor `SteamAPI` client in `src/steam_client.py` to support fetching reviews newer than a given timestamp.
3.  Create the main orchestrator script (`src/main_fetcher.py`?) that implements the scheduled job logic (steps 4.1-4.d).
4.  Create the `Translator` service/functions.
5.  Create the `ReviewAnalyzer` service/functions, including the new LLM prompt for structured data extraction.
6.  Implement the processing logic (steps 4.1-4.2) either within the main script or as separate callable functions/services.
7.  Set up basic `cron` job to run the `main_fetcher`. 